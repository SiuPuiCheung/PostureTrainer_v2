# Deep Research Prompt  Integrating Custom Exercise Routines

## Focus
How can a posture training platform support custom, multi-step exercise routines (e.g., martial arts kata, dance choreography, physiotherapy flows) so users and coaches can author, evaluate, and refine sequences with accuracy, fairness, and explainable feedback?

## 1. Research Objective
Collect actionable knowledge and practical design patterns to implement a lightweight, desktop-first MVP feature that lets users define multi-step routines, validates performance against a template, and returns understandable feedback. Emphasis on methods feasible under a low budget (<500 AUD) and local-first processing.

## 2. Core Research Questions
1. Which existing consumer, professional, or academic systems enable user-defined multi-step movement sequences? What is the granularity of customization (keypose-level, timing, transitions, velocity ranges, style variants)?
2. Which algorithmic approaches best suit sequence validation at MVP scale? Consider: DTW, HMM, sequence embeddings, Transformer-based temporal similarity, graph matching, and simple heuristics.
3. How do platforms handle permitted variability (tempo variation, stylistic deviations, body shape differences, partial occlusion, camera angle changes)? What techniques ensure robust matching without unfair false negatives?
4. What labeling or schema standards (pose taxonomies, semantic tags, thresholds) exist for encoding step definitions usable across domains (martial arts, dance, physio)?
5. Which UX patterns make it easy to author, test, and refine routines (timeline editors, pose library + preview, drag-and-drop segments, auto-extraction suggestions)?
6. How do systems present feedback for multi-step routines (per-step score, aggregated flow score, deviation overlays, replay ghosting, ranked issue list)? Which formats are most actionable?
7. What storage formats and data structures are practical for templates: JSON, state machines, graphs (DAG), or other schema? Which are easiest to version & export?
8. What is the trade-off between real-time (frame/step-by-step) feedback vs. post-session analysis (deeper alignment & metrics)? How to combine both effectively for usability and accuracy?
9. What onboarding best practices (calibration, guided capture, auto-extracted keyframes) reduce creation errors and increase template quality?
10. How do professional/clinical contexts change requirements (e.g., ROM thresholds, evidence, labeling semantics, patient safety)?
11. What adoption pitfalls exist (too rigid templates, overfitted models, confusing feedback) and how are they mitigated in practice?
12. What privacy & IP considerations arise from storing templates that may include proprietary choreography or kata? Best practices for local-only vs. encrypted cloud share.
13. What are practical performance/regulatory trade-offs for local inference, optional edge acceleration, and optional cloud evaluation? (Latency, cost, privacy)
14. How can LLMs increase accessibility and usability (assist routine authoring, convert plain language to structured template, generate tailored corrective narratives)?

## 3. Comparative Landscape
- Identify 812 representative systems across these domains:
  - Martial arts & kata recognition academic work
  - Dance choreography alignment and expressive style work
  - Rehab/physiotherapy tools with ROM and progression tracking
  - Fitness sequencing apps (HIIT / routine trainers)
  - CV toolkits and open-source reference implementations (MediaPipe, OpenPose, YOLO-based solutions)

## 4. Technical Dimensions to Map
| Dimension | Candidate Methods | Focus for Evaluation |
|-----------|-------------------|----------------------|
| Pose representation | 2D landmarks (MediaPipe), 3D estimates (depth, SMPL), angle vectors, learned embeddings | Accuracy vs compute cost |
| Sequence alignment | DTW, HMM, sliding-window matching, Transformer similarity, graph matching | Robustness to tempo & partial matches |
| Key-pose extraction | Clustering, velocity peaks, semantic labeling | Ease of authoring |
| Error quantification | Angle deltas, Euclidean landmark displacement, timing offsets | Interpretability for users |
| Feedback decider | Rule-based thresholds, ML regression, hybrid + LLM for narrative | Explainability & personalization |
| Storage model | JSON schema, workflow graphs, state machines | Extensibility & version control |
| Pipeline | Real-time incremental alignment vs. post-process batch alignment | Latency/accuracy balance |

## 5. UX & Authoring Workflow (Recommended Baseline)
1. Capture or upload a reference performance (video or live capture).
2. Auto-extract candidate key-poses and timing markers (velocity-based peaks).
3. UI: present an editable timeline where users may rename steps, adjust keyframes, add labels (e.g., "balance test", "impact"), and set tolerances.
4. Save as a template (versioned). Option: export/import JSON.
5. Evaluate performance live (per-step) with overlay and immediate corrective hint; run deeper analysis post-session for aggregate metrics.
6. Share or import templates (optional), with encryption or local-only options when IP-sensitive.

## 6. MVP JSON Routine Schema (Sample)
```json
{
  "routine_name": "Karate Kata - Heian Shodan",
  "domain": "martial_arts",
  "steps": [
    {
      "id": 1,
      "label": "Opening Stance",
      "keypose": { "angles": { "left_elbow": 180, "right_elbow": 180 }, "landmarks": [] },
      "duration_ms": 2000,
      "tolerance": { "angle_deg": 15, "timing_ms": 500 },
      "notes": "Hold stance with weight centered"
    }
  ],
  "global_tolerance": { "angle_deg": 20, "timing_ms": 1000 },
  "metadata": { "author": "Coach Name", "created": "2025-11-29", "version": 1 }
}
```

## 7. Alignment Pseudocode: DTW with Tolerance Gating (Minimal MVP)
Function: DTW over reduced angle vector set. Gating: apply per-step and global tolerances.
```
# Inputs: reference_sequence = [f1..fn], live_sequence = [g1..gm]
# Each frame is an angle vector (or joint subset). angle_tol = threshold

function compute_distance_frame(a,b):
    # normalized L2 angle difference across the used angles
    return sqrt(sum( (a_i-b_i)^2 ))

function dtw_alignment(reference, live):
    D = matrix(n+1, m+1, +inf)
    D[0,0] = 0
    for i in 1..n:
        for j in 1..m:
            cost = compute_distance_frame(reference[i], live[j])
            D[i,j] = cost + min(D[i-1,j], D[i,j-1], D[i-1,j-1])
    return backtrack path from D[n,m]

function tol_gated_dtw(reference, live, angle_tol):
    aligned_path = dtw_alignment(reference, live)
    step_results = list()
    for each step in reference defined by index spans:
        compute avg_deviation across matched frames
        pass = avg_deviation <= angle_tol
        step_results.append({step, avg_deviation, pass})
    return step_results, aligned_path
```

## 8. LLM Feedback Prompt Templates (MVP-ready)
- Per-step corrective statement:
  "During step {label}, your left elbow was {delta} off the expected {target}. Try maintaining a {actionable_tip} and practice with a slow tempo."

- Post-session coaching script prompt (pass the metrics):
  "Given these metrics: {step_1: {avg_dev: X, timing: Y}, ...} produce 3 concise coaching tips, 1 practice drill, and a safety note if necessary."

- Natural language -> template authoring prompt:
  "User: I want a 4-step sequence: stance, block, strike, return. Produce a JSON routine template with suggested durations, tolerances, and key-angle expectations for a beginner." 

## 9. Prioritized Metrics (Top 15)
1. Per-step avg angle deviation (selected joints)
2. Timing offset (ms) per step
3. Balance shift (body centroid lateral displacement)
4. Step completion ratio (fraction frames within tolerance)
5. Max joint deviation per step
6. Symmetry index (left/right angles)
7. Smoothness / jerk metric (velocity variance)
8. Posture alignment score (head/shoulder/hip line)
9. ROM conformance (physio contexts)
10. Tempo variance vs reference
11. Confidence: landmark visibility & occlusion flags
12. Composite flow score (weighted aggregate)
13. Ranked steps by deviation (priority list)
14. Session consistency (variance across reps)
15. Fatigue or degradation over time

## 10. Experiments & Test Plan
- Dataset: small curated set with sample kata & dance sequences + variations (tempo, camera angle).
- Compare DTW vs Transformer-embedding alignment with metrics: pass rate, latency, compute cost.
- UX test: authoring time (auto-extract + refine) vs manual authoring.
- LLM prompt L: evaluate clarity/accuracy of generated coaching text from metrics.
- Performance test: local inference latency on older laptop (target <150ms per frame for reduced angle set).

## 11. Risks & Mitigations
- False negatives: show confidence & provide explanation; permit tolerance widening.
- Over-specialization: provide style templates & mirror/variant options.
- IP/privacy: default local-only templates; encrypted share; explicit consent for sharing.
- Low-end hardware: low-resource mode (coarse landmarks, lower FPS).

## 12. Deliverables from Research
- Comparative matrix of 812 tools/approaches.
- JSON routine schema: extended sample and quick spec.
- Lightweight DTW implementation & test harness (pseudocode + sample runner).
- LLM prompt templates for authoring and feedback.
- Prioritized metrics list.

## 13. Success Criteria
- Routine authoring time  10 minutes for a 10-step sequence.
- Real-time latency  150 ms per frame (reduced angle vector) on target hardware.
- User comprehension rate of feedback  80% on surveys.
- At least 50% re-use of created routines within 7 days.
- Template tolerance & style modes cover  90% of typical sequences.

---
Use this as a practical research and prototyping guide to build a sequence-authoring and alignment feature for the platform.
